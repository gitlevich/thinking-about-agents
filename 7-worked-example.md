# A Walk Through My Tokenizer (Annotated)

The previous pieces were theory and toy code. This one is a recording.

What follows is a real-time word painting: me turning on the tokenizer, letting it run, and watching what it does. I’ve
only done light editing for readability. Between paragraphs I’ve added short notes in Agent Language (AL): frames,
contrasts, observer vs agent mode, capture, regulator, bandwidth.

⸻

Entering the narrative space, capturing what’s been going on between last night and today. I’ve been chatting with
ChatGPT, refining my insight that I basically run a tokenizer in my head and that my attention is captured by a
narrative.

[AL: Agent mode turns on. Goal = “capture what’s been going on.” Frame = “recent events + current room.” Tokenizer is explicitly noticed as a process.]

It captures so much attention that—sorry, that’s not about that, restating. A thought went away, I went chasing it, then
I—I mean, God of me. I made an executive decision to cut it and switched my attention into the mode of an observer,
floating through beautiful space, real space, as seen with my eyes—the world, the entire sensorium, along all of the
contrasts I collapse at the moment.

[AL: Micro-capture, then regulator fires. Explicit mode switch AGENT → OBSERVER. Frame widens: more contrasts, higher resolution, low narrative pressure.]

So it’s this full-resolution, full frame-rate, analog, unquantized experience. As an agent, I process experience frame
by frame. Actually, as an observer, I experience my observations frame by frame. They buffer, aggregate, and I see them
in the same embedding space. They coincide. The sky is blue. The music is beautiful and loud.

[AL: Frames exist even without a narrative. Embedding here = lived multi-contrast space before tokens.]

Because I am a native Russian speaker and English became my primary language, the language needed for me to communicate
became a matter of survival. I used to pride myself in Russian on a surgical command of words: I could be precise, paint
emotion with words. There were times when a story wanted to come out, and I’d sit at a typewriter or with paper and
write it from beginning to end. In the beginning I didn’t know how it would end. It was computationally irreducible.
When it finished writing itself, I knew.

[AL: New frame: autobiographical. Goal shifts from “describe now” to “explain tokenizer provenance.” Word painting as irreducible generative process.]

Decoherence. In decoherence, I’m simply floating in the current frame of reality in 3D. I see the television in front of
me and the bookcase to its left. The bookcase is light plastic, white, translucent, disassemblable into blocks. It came
with me from New York, where I bought it probably in 2008, followed me to storage in San Bruno, then to 9 Lafayette for
about thirteen years, then to 1550 Mission where it shyly hid: one squat piece in the living room and a couple of
awkward pieces in the second bedroom / office.

[AL: Start in present-room frame, then fall into the bookcase trajectory: New York → storage → 9 Lafayette → 1550 Mission. Same topology as in the “capture” essay.]

That extra space had a sucking effect and decohered the apartment experience, and it correlated with my father’s seven
months of utter disaster, followed by his death.

[AL: Sigil hit: “my father’s seven months,” “his death.” Bookcase chain lands in a trauma well. Classic gravity well.]

But yes, I’m describing my experience right now. I don’t need to point my attention at how I departed in an arbitrary
direction into a narrative about my father while I was describing the scene in front of me.

[AL: Regulator surfaces. Recognizes capture: the narrative drifted from “describe room” to “father” without explicit choice.]

So that’s how I think. Now I’ve been pulled back by the God of me, the gatekeeper—the regulator—a simple meta-agent I
can access. It lets me flip between being here, now, in the frame, with whoever is next to me (if anyone), in this
particular environment, and being lost in a narrative.

[AL: Regulator named explicitly. Its role = mode switching AGENT ↔ OBSERVER over the same physical frame.]

I can describe this frame. As I describe, it will probably change, although since I’m just sitting in my room, not
materially, so I can proceed describing with a reasonably long exposure: expose correctly and just go left to right
describing the chairs on my left, around a table of light reused wood, golden in the northern light of the blue sky from
the balcony, slightly shaded by the next balcony, on this 19th floor overlooking the City Hall of San Francisco on a
cold December day.

[AL: New goal: “describe the frame carefully.” Long-exposure metaphor = low frame rate, high resolution. Word painting aligned with observer frame.]

See what I mean? Again I ran away into a tangential narrative. It was generation that just ran away with me. There is
nothing controlling my direction of narrative.

[AL: Self-diagnosed drift: agent mode following local gradients; regulator temporarily idle.]

If I pull away now and then—if I’m yanked out of a particular narrative—I’m just sitting here, experiencing the black
rectangle of the television against the warm yellowish, pleasantly peach wall under a white ceiling, left of a huge
wall-to-wall, floor-to-ceiling window to the balcony, in front of which is the centered view of the City Hall and St.
Mary’s Cathedral, the one I call “Maytag” for its shape.

[AL: Regulator fires again. Frame re-expands to present room. “Maytag” is a sigil: a label for a shared world around that building.]

Okay, see? Again I ran away. I was generating and then I got attracted somewhere and went straight down toward that
gravity. It wanted to go there. But is that why I’m tokenizing? No. I’m tokenizing to retain visuals, but I can’t help
going on tangents.

[AL: Clear AL diagnosis: gravity wells tug the narrative. Two goals collide: retain visuals vs follow associations. Capture pressure vs intended goal.]

What we’re doing right now are my observations over thinking. It’s an attempt at metacognition using my own executive
mind and this now-native requirement to tokenize the world into words. I prided myself on shaping what I feel in my
sensorium into the right words—to paint with words.

[AL: Meta-frame: goal = “observe thinking process.” Tokenizer compulsion rooted in bilingual history. Word painting = mapping sensorium frame → token stream.]

This painting shouldn’t just make you vaguely imagine what I see. It should make you see fragments of it in the right
color, light, saturation—a faithful reproduction.

[AL: Preference over word paintings: high resolution along visual contrasts in the listener’s reconstructed frame.]

Yet, if I sit firmly in observing mode, and nothing in the frame is changing, I don’t need to generate a narrative. I
can simply sit and be with the space, in the space, and if people are there, with those people, instead of interacting
through tokens.

[AL: Pure observer mode: stable frame, low frame rate, no narrative. Direct entanglement with environment/others; tokenizer idle.]

That’s a highly expensive activity, though, and my performance depends on many factors, because my brain is overloaded
with the tokenizer—the transcoding from the frequency domain of what I feel along all my resolved contrasts, into the
time domain of highly compressed narrative. My thoughts meander; I might suddenly tangent into something orthogonal.

[AL: Cost model explicit: bandwidth spent on serialization (multi-contrast frame → 1-D token stream). Meandering = capture risk.]

Okay, so I am now in generative experience. I’m generating. I’m running the tokenizer at some cost to cognition, but I’m
not paying much attention to it. It just saps resources. I could be sitting here not talking, just being, and that’s
very enjoyable.

[AL: Agent mode acknowledged. Tokenizer as background process consuming bandwidth even when not foreground. Contrast with cheap observer mode.]

So I think this concludes this exploratory session into my metacognition recorded as an experiment—me observing me
doing. I wonder if this can be helpful to people who actually develop language models, because I have one in my head,
and I kind of think the way that it does.

[AL: Meta-goal wraps: “exploratory session” complete. Hypothesis: internal tokenizer + control loop is structurally similar to an LM.]

We went around this with ChatGPT and got to the point that we agree my attention is mostly downstream from the
tokenizer. I process tokens too, in narrative mode, in agent mode. When I switch to agent mode I have a goal, with
preferences driven by that goal—or a goal emerging from preferences.

[AL: Explicit AL: agent = observer + goal + preference; attention shaped by the token stream it produced moments ago.]

The high-bandwidth, low-energy option is simply: don’t digitize it. Don’t tokenize. Just look. Be in it, with it, and
don’t tell a story. Leave all narratives alone.

[AL: Clean AL statement: observer mode = high bandwidth, low energy because no serialization. Frames without narratives.]

Right now I’ve tricked myself by creating a parasitic narrative—the compulsion to digitize, to tokenize—but I’m running
it at the lowest possible frame rate so I can maintain metacognition and just generate completions.

[AL: Hybrid mode: observer frame plus sparse token layer. Low frame-rate narrative used to keep meta-attention online.]

So yes, I’ve done a few circles around it—maybe three iterations of trying to say something specific. But this was
simply a demonstration of what I think metacognition is, and I’d like your opinion on it.

[AL: Self-diagnosed looping: multiple passes over the same structure (observer/agent, tokenizer, regulator). Metacognitive goal over content goal.]

⸻

For me, this recording just shows that everything in the earlier pieces actually appears in lived time: mode switches,
shrinking and widening frames, gravity wells, sigils, bandwidth as a felt cost, word paintings as projections.

The theory wasn’t invented from nothing. It was reverse-engineered from sessions like this.
